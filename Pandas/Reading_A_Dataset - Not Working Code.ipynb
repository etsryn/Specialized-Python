{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go8UTJZR63k_"
      },
      "source": [
        "# Reading Datasets in Different File Formats\n",
        "\n",
        "> #### When working with data, we often encounter datasets stored in various file formats. Python provides multiple libraries to efficiently read and process these files. Among them, **Pandas** is one of the most widely used libraries for handling structured data.\n",
        "\n",
        "> #### `Pandas` offers built-in functions to read and write datasets in different formats, including **Excel** (`.xlsx`), **CSV** (`.csv`), **JSON** (`.json`), **TSV** (`.tsv`), **Parquet** (`.parquet`), and more. This guide covers how to work with these file formats effectively.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8H68BZ1EE6I"
      },
      "source": [
        "# Installing Required Libraries\n",
        "- Install Pandas (*if not already installed* )\n",
        "  - If Installing on `Google Colab`\n",
        "    - `!pip install pandas`\n",
        "  - If Installing on `Command Prompt` or `Powershells` like of `VS Code`\n",
        "    - `pip install pandas`\n",
        "\n",
        "```\n",
        "!pip install pandas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ7CIR28EdYP"
      },
      "source": [
        "- Install OpenPyXL (*if not already installed* )\n",
        "  - If Installing on `Google Colab`\n",
        "    - `!pip install openpyxl`\n",
        "  - If Installing on `Command Prompt` or `Powershells` like of `VS Code`\n",
        "    - `pip install openpyxl`\n",
        "\n",
        "```\n",
        "!pip install openpyxl\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9x-_aBTExP0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR7moeInEylr"
      },
      "source": [
        "# Importing Required Library\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "### What's `as pd` ?\n",
        "\n",
        "- This assigns the **alias** `pd` to the **Pandas library**\n",
        "- Instead of writing `pandas.function_name()`, you can simply use `pd.function_name()`\n",
        "- It reduces typing effort and improves code readability\n",
        "- **Industry Standard:** Almost all Python developers use pd as the alias\n",
        "- **Saves Time:** Instead of writing `pandas.DataFrame()`, we write `pd.DataFrame()`\n",
        "- **Improves Readability:** Shortens code while keeping it understandable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2aEfNcCEPi6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CenAHjX783Gb"
      },
      "source": [
        "# Reading Excel (`.xlsx`) File\n",
        "\n",
        "- Pandas provides the `read_excel()` function to load Excel files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv_rSr5-EmU8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"data.xlsx\", engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKlM1tCbF_N4"
      },
      "source": [
        "> The `engine=\"openpyxl\"` parameter ensures compatibility with `.xlsx` files although it is optional to use\n",
        "\n",
        "> Pandas can automatically detect and use openpyxl if it is installed, if you simply run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLhY0jqVGZR5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"data.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOT730PJGdlO"
      },
      "source": [
        "> Pandas will internally select `openpyxl` as the engine by default if the file format is `.xlsx`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecvHZ_dSGqA6"
      },
      "source": [
        "### When Should You Explicitly Use engine=\"openpyxl\"?\n",
        "\n",
        "- To Avoid Compatibility Issues:\n",
        "\n",
        "  - If multiple engines (`xlrd`, `openpyxl`, `odf`) are installed, explicitly specifying `engine=\"openpyxl\"` ensures Pandas does not default to an incompatible engine\n",
        "\n",
        "- Older Pandas Versions (`Before 1.2.0`):\n",
        "\n",
        "  - Before `Pandas v1.2.0`, `xlrd` was used for `.xlsx` files, but newer versions of `xlrd` dropped support for `.xlsx`\n",
        "\n",
        "- In such cases, explicitly setting `engine=\"openpyxl\"` avoids errors\n",
        "\n",
        "- Writing `.xlsx` Files (`to_excel()` method):\n",
        "\n",
        "If you want to write an Excel file, specifying `engine=\"openpyxl\"` ensures proper formatting:\n",
        "\n",
        "```\n",
        "df.to_excel(\"output.xlsx\", engine=\"openpyxl\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV8urWC9Hcoj"
      },
      "source": [
        "## Final Recommendation\n",
        "- If only working with `.xlsx`, you can **omit** `engine=\"openpyxl\"` if openpyxl is installed.\n",
        "\n",
        "- If dealing with multiple formats or ensuring compatibility, explicitly specify `engine=\"openpyxl\"` to avoid unexpected issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_T6_CmCH0bC"
      },
      "source": [
        "## Reading Specific Sheets from an Excel File\n",
        "- Use `sheet_name` to specify which sheet to read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvvPBoejH4wo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"data.xlsx\", sheet_name=\"Sheet1\", engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA737g3iIFd-"
      },
      "source": [
        "## Reading Multiple Sheets into a Dictionary of DataFrames\n",
        "- This will load all sheets into a `dictionary` where `keys` are `sheet names`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSLfRVICITHD"
      },
      "outputs": [],
      "source": [
        "dfs = pd.read_excel(\"data.xlsx\", sheet_name=None, engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlWx10EWIbAe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlOUq_2oIb69"
      },
      "source": [
        "# Reading (`.csv`) File\n",
        "\n",
        "- Pandas provides the `read_csv()` function to load **CSV** Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q1JxQBvIrQW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9j1BnQAIvZ5"
      },
      "source": [
        "### Reading **CSV** with Custom Delimiters\n",
        "> Semicolon-separated file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjvdqZiDI315"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWag8-bkJQ9n"
      },
      "source": [
        "### Understanding **delimiter** in `pd.read_csv()`\n",
        "\n",
        "- The delimiter parameter in `pd.read_csv()` is used to specify the character that separates values in a CSV file. By default, CSV files are **comma-separated** (`delimiter=\",\"`), but sometimes, data might be separated by other characters like **semicolons** (`;`), **tabs** (`\\t`), or **pipes** (`|`)\n",
        "\n",
        "### How It Works?\n",
        "\n",
        "- `pd.read_csv(\"data.csv\")` assumes that the default separator is a **comma** (`,`)\n",
        "\n",
        "- If the data uses **semicolons** (`;`) instead of commas to separate values, Pandas will misinterpret it as a `single-column dataset`\n",
        "\n",
        "- The `delimiter=\";\"` argument tells Pandas to correctly **split columns based on semicolons**\n",
        "\n",
        "### Example Dataset (`data.csv` with `;` as delimiter)\n",
        "- Contents of `data.csv` (Incorrect Interpretation without delimiter)\n",
        "\n",
        "```\n",
        "Name;Age;Country\n",
        "Alice;25;USA\n",
        "Bob;30;UK\n",
        "Charlie;28;Canada\n",
        "```\n",
        "\n",
        "-  If we load this without specifying the delimiter:\n",
        "\n",
        "```\n",
        "df = pd.read_csv(\"data.csv\")  # Default delimiter is \",\"\n",
        "```\n",
        "\n",
        "-  Incorrect Reading\n",
        "> Pandas reads the entire row as a single column because it expected `,` but found `;` instead!\n",
        "\n",
        "```\n",
        "        Name;Age;Country\n",
        "0     Alice;25;USA\n",
        "1       Bob;30;UK\n",
        "2  Charlie;28;Canada\n",
        "```\n",
        "\n",
        "- Correcting It Using delimiter=\";\"\n",
        "\n",
        "```\n",
        "df = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
        "```\n",
        "- Correct Output:\n",
        "> Now, Pandas correctly splits the columns based on `;` instead of treating the entire row as one value\n",
        "\n",
        "```\n",
        "     Name  Age Country\n",
        "0   Alice   25     USA\n",
        "1     Bob   30      UK\n",
        "2  Charlie   28  Canada\n",
        "```\n",
        "\n",
        "## Other Common Delimiters:\n",
        "\n",
        "| Delimiter        | Example Usage                                     |\n",
        "|------------------|---------------------------------------------------|\n",
        "| Comma (`,`)      | Default separator in CSV files                    |\n",
        "| Semicolon (`;`)  | Used in some European datasets                    |\n",
        "| Tab (`\\t`)       | Often used in `.tsv` (Tab-Separated Values) files |\n",
        "| Pipe (`|`)       | Used in logs or structured text formats           |\n",
        "\n",
        "### Summary\n",
        "> The delimiter parameter ensures Pandas correctly interprets different column separators\n",
        "\n",
        "> Use `delimiter=\";\"` if your dataset uses semicolons instead of commas\n",
        "\n",
        "> Helps when working with `European CSVs`, `log files`, or `custom-formatted data`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7jIedkoNZKN"
      },
      "source": [
        "# Reading `.json` File\n",
        "- Pandas provides the `read_json()` function to load **CSV** Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J02pfjc5NyCT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_xyU6QOC13"
      },
      "source": [
        "- Sometimes it needs additional parameters depending on the structure of the **JSON** file\n",
        "\n",
        "|Parameter      | Description |\n",
        "|---------------|-------------|\n",
        "| orient        | Defines JSON structure (e.g., \"records\", \"columns\", \"index\", \"split\")        |\n",
        "| lines         |\tIf True, reads JSON where each line is a separate record (useful for large datasets) |\n",
        "| dtype         |\tSpecifies data types for each column |\n",
        "| convert_dates |\tAutomatically converts date columns |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X55AXLfPE-5"
      },
      "source": [
        "# Reading `.parquet` or .`pqt` Files\n",
        "\n",
        "Install Required Library\n",
        "\n",
        "```\n",
        "!pip install pyarrow\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z9Esn3eTSJM"
      },
      "source": [
        "Reading a Parquet File:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiDGWsheTUxs"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"data.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUE_k1W8UbHF"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
